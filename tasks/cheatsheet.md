# План лекций

## Краткое введение в устройство операционных систем и управление памятью

#### Процессор

1. Процессор может выполнять специальные инструкции, которые зависят от архитектуры - машинный код. 
2. Очень упрощенно: процессор может оперировать регистрами (внутрипроцессорные сверхбыстрые ячейки памяти) и основной памятью. Помимо этого между процессором и основном памятью существует несколько уровней кэша. 
3. Современные процессоры в основном многоядерные.
4. Инструкции процессора оперируют основной памятью и регистрами. Писать и читать в регистры  намного быстрее. 

Следующая программа на языка `C`
```C
#include<stdio.h> 

 
int main(int argc, char *argv[]) { 
    int a = 2; 
    int b;  

    b = (a + 17) * 9; 

    printf("%d\n", b); 
 
    return 0; 
} 
```

может транслироваться в программу на ассемблере (упрощенно: удобочитаемая форма машинного кода) 

```Python
# int main(int argc, char *argv[]) { 
   push   %rbp 
   mov    %rsp,%rbp 
   sub    $0x20,%rsp 
   mov    %edi,-0x14(%rbp) 
   mov    %rsi,-0x20(%rbp) 

# int a = 2; 
   movl   $0x2,-0x8(%rbp) 

# int b; 
# b = (a + 17) * 9; 
   mov    -0x8(%rbp),%eax 
   lea    0x11(%rax),%edx 
   mov    %edx,%eax 
   shl    $0x3,%eax 
   add    %edx,%eax 
   mov    %eax,-0x4(%rbp) 

# printf("%d\n", b); 
   mov    -0x4(%rbp),%eax 
   mov    %eax,%esi 
   lea    0x98(%rip),%rdi        # 0x714 
   mov    $0x0,%eax 
   callq  0x520 <printf@plt> 
```

`%eax`, `%..`  - это регистры. `mov` - скопировать данные из источника в приемник (регистр, ячейка основной памяти).

Исполняемые файлы (`PE` (.exe) для ОС семейства Windows, `ELF` для \*nix) и динамические библиотеки (`.dll` и `.so`) содержат в том числе машинный код в бинарном виде, который может прямо выполняться процессором.  

#### Управление памятью
1. Очень упрощенно - каждый процесс имеет своё виртуальное адресное пространство . Это пространство разделено на регионы - станицы фиксированного размера (на самом деле может быть по разному). 
2. Каждая страница отображается (или не отображается) в страницу физической памяти 
3. Страницы двух разных процессов могут отображаться в одну и ту же страницу физической памяти. 
4. Когда не хватает физической памяти неиспользуемые страницы могут скидываться на диск. 
Процесс - оcновная единица выполнения операционной системы (очень условно). Работает в своём виртуальном адресном пространстве. Имеет как минимум один поток. 
5. В \*nix системах есть системный вызов `fork`, который позволяет быстро создать копию процесса с помощью механизма `copy-on-write`.


#### Процессы и потоки
1. Процесс - основная единица выполнения операционной системы (очень условно). Работает в своём виртуальном адресном пространстве. Имеет как минимум один поток. 
2. Поток - линейный процесс выполнения набора инструкций. В рамках процесса в одном и том же адресном пространстве могут выполняться несколько потоков.  Основная цель - параллельное выполнения каких-то действий (на многоядерных процессорах оно действительно может работать параллельно).  


## Docker
1. Docker позволяет обеспечить изоляцию и удобное развертывание приложений в Linux-системах (ограничив доступ к файлам, памяти, процессору, подменив сетевые интерфейсы, `userland` и так далее).
2. Используются специфичные механизмы ядра Linux - `cgroups`
и `namespaces`. 
3. Docker можно установить под любую распространенную операционную систему, но для Windows или macOS требуется использования системы виртуализации, в которой запускается ядро Linux, что негативным образом сказываетсяна производительности и расходовании ресурсов.
4. Используются специфичные механизмы ядра Linux - `cgroups`
и `namespaces`. 
5. C помощью Docker удобно автоматизировать процесс
развертывания приложений и запуска в изолированном окружении.
6. `Образ` (`image`) - это неизменяемый образ файловой системы и набор вспомогательной мета-информации. Образы могут состоять из слоев - срезов файловой системы, которые накладываются друг на друга. Например, образы двух разных версий Python могут иметь один общий слой - базовый набор библиотек операционной системы.  
7. Готовый образ можно `импортировать` на локальную из удаленного реестра.
8. Образ можно собрать локально, с помощью инструкций в `Dockerfile`.
9. Контейнер - процесс, который запускается в изолированном окружении на основе образа. При запуске создается слой, который накладывается на образ. Контейнер можно запустить, остановить, перезапустить, удалить (в этом случае все данные будут потеряны), создать на основе работающего контейнера новый образ.

## Python: потоки, процессы, примитивы синхронизации

#### СPython
Python - скриптовый язык программирования со строгой динамической типизацией 

Основная реализация: CPython. Другие: PyPy, GraalPython, Jython, различные модификации CPython.  

Интерпретатор CPython конвертирует исходный код в специальный байт-код стековой машины 

Cтек - структура данных с порядком LIFO (последним пришёл — первым ушёл). Есть две операции - положить (push) и снять (pop). Команды байт-кода оперирует стеком. Пример: функция: 

```python
def add(a, b): 
    return a + b + 2 
```

преобразуется в байт-код  

```python
0  LOAD_FAST                0 (a)               
2  LOAD_FAST                1 (b) 
4  BINARY_ADD 
6  LOAD_CONST               1 (2) 
8  BINARY_ADD 
10 RETURN_VALUE 
```

1. Ядро интерпретатора CPython ()- большой цикл, в котором последовательно обрабатываются инструкции байт-кода 
2. CPython реализована автоматическая модель управления памятью, нет необходимости вручную удалять объекты. Основа - счетчик ссылок и дополнительным сборщиком мусора, который работает в случае циклических ссылок .
3. СPython в общем случае очень неэффективный интерпретатор, как по эффективности использования памяти, так и по скорости выполнения программ (по состоянию на 3.11)
4. По состоянию на 3.11 в CPython существует `GIL` (глобальная блокировка интерпретатора), в результате чего только один пользовательский поток может выполняться в конкретное время, это обеспечивает потокобезопасность (данные интерпретатора и нативных расширений не могут быть повреждены, когда два потока работают параллельно) и максимальную производительность однопоточных программа, но в то же время осложняет разработку вычислительно-интенсивных программ.
5. Некоторые библиотеки (`NumPy` и т.д.) при выполнении определенных функций отпускают GIL. 

#### Потоки
1. Для запуска потока нужно создать экземпляр класса `Thread` из модуля `threading`, передав туда функцию, которая будет запущена в отдельном потоке и аргументы.
2. Создание потоков - тяжелая операция. Можно переиспользовать потоки для различных задач с помощью концепции `Executor` (модуль `concurrent.futures`) или `ThreadPool` (модуль `multiprocessing.dummy`).
3. При обращении к общим ресурсам из разных потоков нужно использовать механизмы синхронизации (`Lock`, `RLock`, `Semaphore`, `Queue`, `Event`, `Condition`).


#### Процессы
1. Так как в CPython пока есть `GIL`, использование потоков для вычислительно-интенсивных задач не принесет выигрыша в производительности. 
2. Альтернатива - `multiprocessing`. Создание отдельных (дочерних) процессов, с интерпретаторами Python. Они могут выполнять какие-то вычислительно сложные функции.
3. Под разные системы используются разные подходы к запуску дочерних процессов (`fork`, `spawn`, `forkserver`). 
4. Для синхронизации и доступа к общим данным используются различные механизмы (Pipe, Manager, Lock, Queue, и т.д.)
5. Для работы с большими данными можно использовать memory-mapped files.

## Hadoop

### HDFS
1. Hadoop Distributed File System - распределенная файловая система, которая развивается в рамках проекта Hadoop. С точки зрения пользователя представляет собой классическую иерархическую файловую систему (обратный пример - object storage), с файлами, директориями, правами доступа. 
2. Файлы хранятся распределенно, реплицируются, система устойчива к отказам оборудования. 
3. HDFS имеет свои ограничения, которые отличают её от классических локальных файловых систем, а дизайн изначально был рассчитан на использование в рамках обработки данных с помощью MapReduce. 
4. Система горизонтально масштабируема, запускалась на кластере ~ 4000 машин.
5. HDFS необязательно использовать вместе с MapReduce, система может использоваться независимо.
6. В целом состоит из `NameNode` - машин(ы), на которой хранятся мета-данные, DataNode - машины, на которых хранятся данные.
7. Файлы делятся на блоки (по умолчанию 128Мб)
8. Каждый блок хранится на какой-то `DataNode`.
9. Каждый блок файла реплицируется по другим `DataNode` по сети (по умолчанию на 3 узла - `replication factor`)
10. `NameNode` отслеживает каждый состояние узлов.
11. Если узел стал недоступен, то блок автоматически до-реплицируется.
12. `DataNode` умеют общаться друг с другом
13. HDFS Federation позволяет использовать множество NameNode для горизонтального масштабирования
14. Есть система контроля доступа и авторизации

### YARN
1. Система управления ресурсами, составная часть Apache Hadoop, начиная с версии 2.0. 
2. Мотивация для создания YARN: есть большой кластер и нужно запускать на нём какие-то задачи, выделяя каждой задаче необходимые ресурсы (ограничивая и квотируя), наблюдать за состоянием задач и оборудования.
3. `Resource Manager` - управляет ресурсами кластера. Обычно кластер имеет только один основной Resource Manager
4. `Node Manager` - узлы, которые отвечают за запуск задач и приложений (контейнеров). На тех же машинах, что и `DataNode`.


### MapReduce
1. Модель вычислений и тип организации фреймворка вычислений. Пользователю нужно написать функции `map` и `reduce`, указать выходные и выходные данные (обычно на каком-то распределенном хранилище, например `HDFS`). Опционально указываются `combiner` и функции для сортировки и разделения данных. 
2. Важное свойство - Data Locality.
3. Hadoop MapReduce - просто приложение для `YARN`.
4. Популярен до середины 2010-х годов, есть определенные проблемы (долгий запуск, сложности в администрировании, стоимость, проблемы в итерационными алгоритмами, сложность в программировании). 
5. До сих пор используется.

### Hive
1. Преобразует запрос на диалекте SQL - HiveSQL в последовательность MapReduce задач (не только). Данные хранятся в файлах на HDFS (или других распределенных хранилищах, интерпретируются как таблицы). 
2. К "таблицам" можно обращаться из других систем (Apache Spark, Trino, и т.д.)


### ZooKeeper
1. Распределенный координационный сервис для распределенных приложений, предназначенный для управления конфигурациями, синхронизацией, обмена вспомогательными данными между узлами. 
2. `ZooKeeper`, очень упрощенно, можно рассматривать как некоторый аналог примитивов синхронизации, которые используются при написании многопоточных приложений.
3. Позволяет распределенным приложениям координироваться друг с другом, образуя некоторую иерархическую древовидную структуру, наподобие обычной файловой системе, к каждому узлу которой можно присвоить некоторое значение или семантику. Данные хранятся в памяти, что позволяет достигать высокой производительности и минимизировать задержки. 
4. Упор на высокой производительности, масштабируемость, надежность и отказоустойчивость
5. Гарантируется строгая последовательность операций записи и чтения, что позволяет реализовать сложные алгоритмы синхронизации на стороне клиента.

### Spark
1. Фреймворк для аналитических вычислений и распределенной обработки больших данных. 
2. Устраняет недостатки Hadoop MarReduce - данные хранятся в памяти (в основном), возможно организация online и итерационных вычислений.
3. Изначально применялась концепция `RDD`. Минус - невозможно оптимизировать хранение данных, вычисления, код на других языках (кроме JVM) неэффективен.
4. Новый подход: `SparkSQL`, `Dataset` и `DataFrame`. Данные хранятся off-heap, могут храниться по колонкам. 
5. Pandas API и SQL API.
6. Есть библиотеки машинного обучения - `MLlib` и для работы с большими графами - `graphX`.

### Ray
1. Tasks
2. Actors
3. Objects


## Общие вопросы
1. Большие данные - история. Концепция "трех V".
2. "Теорема" CAP.
3. OLTP и OLAP.
4. Хранение данных по строкам или колонкам. 
5. \* Raft, алгоритм алгоритм для решения задач консенсуса в распределенных системах.
6. \* Рандомизированные и вероятностные алгоритмы на больших данных (HyperLogLog, BloomFilter)

## Литература:
1.  https://www.internalpointers.com/post/introduction-virtual-memory
2.  https://habr.com/ru/post/436606/ 
3.  https://www.kernel.org/doc/gorman/html/understand/understand006.html 
4.  https://assets.bitbashing.io/papers/concurrency-primer.pdf
5.  https://github.com/heathermiller/dist-prog-book 
6.  https://docs.python.org/3/library/multiprocessing.html 
7.  https://docs.python.org/3/library/threading.html
8.  https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html
9.  https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html
10. https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html
11. http://greenteapress.com/semaphores/LittleBookOfSemaphores.pdf 
12. https://spark.apache.org/docs/latest/
13. https://ray.io/docs/ 
14. https://docs.docker.com
15. https://www.adaltas.com/en/2021/06/03/linux-overlay-filesystem-docker/

